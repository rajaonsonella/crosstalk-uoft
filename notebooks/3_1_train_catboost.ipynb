{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaonsonella/crosstalk-uoft/blob/main/notebooks/3_1_train_catboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQP9auNa5Yyg"
      },
      "source": [
        "# Set up\n",
        "\n",
        "‚öôÔ∏è Step 1: Set your notebook to GPU\n",
        "\n",
        "The next two cells take ~2 min.... start running them now while we talk! üëáüëá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MYJ9lwd5Yyi"
      },
      "outputs": [],
      "source": [
        "# get workshop code\n",
        "import os\n",
        "import sys\n",
        "IN_COLAB = os.getenv(\"COLAB_RELEASE_TAG\")\n",
        "if IN_COLAB:\n",
        "    !git clone https://github.com/rajaonsonella/crosstalk-uoft\n",
        "    sys.path.append('./crosstalk-uoft')\n",
        "else:\n",
        "    sys.path.append('..')\n",
        "!pip install -r crosstalk-uoft/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIDtPhRE5e8I"
      },
      "outputs": [],
      "source": [
        "# Download data from google drive\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "file_ids = {'test_inputs' : '1Gyv_ldUTi0Ymy6wVMfruAO0UraCQ70CR',\n",
        "            'train': '11S5p0QgP1X9rOFiIjNSLydLenJwm7hle'}\n",
        "\n",
        "for name, file_id in file_ids.items():\n",
        "    filename = f'crosstalk_{name}.parquet'\n",
        "    if not os.path.exists(filename):\n",
        "        gdown.download(id=file_id, output=filename, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtTgY1VZVyGP"
      },
      "source": [
        "Or, if you have the file located in your drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUqVczIVVwo3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QEKqXK15Yyj"
      },
      "source": [
        "# Load the train datasets\n",
        "\n",
        "See the bonus content from last notebook to get a peek under the hood of the data loaders\n",
        "\n",
        "Or check it out in the files you downloaded to colab on the left üëà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBO_PAHSEkF8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataset import basic_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eurf4tVS5Yyj"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = basic_dataloader('crosstalk_train.parquet', x_col=\"AVALON\", y_col = 'DELLabel', max_to_load=1000) # fingerprints available: 'ATOMPAIR', 'MACCS', 'ECFP6', 'ECFP4', 'FCFP4', 'FCFP6', 'TOPTOR', 'RDK', 'AVALON'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jLnIi8_6szm"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc65CZG46_jM"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n526wmlp8Pwn"
      },
      "outputs": [],
      "source": [
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5766Us825Yyk"
      },
      "source": [
        "# Let's train catboost classifier and see how well it fits the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3S2HQif7f97"
      },
      "source": [
        "üêû do you see a CUDA error? raise your hand now and brag about it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Peao1Ylc5Yyl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import catboost as cb\n",
        "from eval import BinaryEvaluator\n",
        "params = {\n",
        "                'random_strength': 2, # only non-default hyperparam, default is 1\n",
        "                'random_seed': 1234,\n",
        "                'verbose': 0,\n",
        "                'loss_function': 'Logloss',\n",
        "                'task_type': 'GPU',\n",
        "                'devices': '0'\n",
        "            }\n",
        "model = cb.CatBoostClassifier(**params)\n",
        "model.fit(X_train, y_train)\n",
        "yp = model.predict_proba(X_train)[:, 1] # or validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPNuDMjgZR9G"
      },
      "outputs": [],
      "source": [
        "eval = BinaryEvaluator(X_train.toarray(), y_train)\n",
        "metric_dict = eval.compute_metrics(yt=y_train, yp=yp) # or validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waTE3Hl99cPX"
      },
      "outputs": [],
      "source": [
        "for metric_name, metric_value in metric_dict.items():\n",
        "    print(f'{metric_name:20s}: {metric_value:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knDqyMms5Yyl"
      },
      "source": [
        "# How well does it generalize though? Let's try 5-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_-ubHP85Yyl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_cv = cb.CatBoostClassifier(**params)\n",
        "metric_dict_cv = eval.CV_model(model_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvxp6AWI_cQ4"
      },
      "outputs": [],
      "source": [
        "for metric_name, metric_value in metric_dict_cv['mean'].items():\n",
        "    print(f'{metric_name:20s}: {metric_value:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob58G6gM5Yyn"
      },
      "source": [
        "# Submit predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWfg9wXOB4SV"
      },
      "source": [
        "Update the next cell with your team name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Y1583bB0og"
      },
      "outputs": [],
      "source": [
        "team_name = 'demo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "340_MENj5Yyn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_test = basic_dataloader('crosstalk_test_inputs.parquet', x_col=\"AVALON\", y_col = None, max_to_load = None, chunk_size = 20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRoWNPsCFojt"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deBOnd6xCE01"
      },
      "outputs": [],
      "source": [
        "yp = model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTd-5y9AYisH"
      },
      "source": [
        "Upload this baseline to kaggle and check out the leaderboard!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVBvnHsRiFeM"
      },
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "from pyarrow import parquet as pq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqhhz-IVh8PK"
      },
      "outputs": [],
      "source": [
        "pf = pq.ParquetFile('crosstalk_test_inputs.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBCiwuXriQ4J"
      },
      "outputs": [],
      "source": [
        "preds = pf.read(columns = ['RandomID']).to_pandas()\n",
        "preds['DELLabel'] = yp\n",
        "display(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enLD8sg7btNE"
      },
      "outputs": [],
      "source": [
        "preds.to_csv(f'{team_name}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbbpQ2GM5Yyl"
      },
      "source": [
        "# Let's compare it against some sklearn baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bztUGo6eAYf9"
      },
      "source": [
        "‚ö†Ô∏è these next cells are slow to run! Start them now and come back in 5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzqCfWDX5Yym"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from eval import get_baseline_models\n",
        "\n",
        "eval = BinaryEvaluator(X_train.toarray(), y_train)\n",
        "baselines = get_baseline_models()\n",
        "baselines_res = {}\n",
        "\n",
        "for m in baselines:\n",
        "    baselines_res[m] = eval.CV_model(baselines[m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPzHpmOrAirD"
      },
      "outputs": [],
      "source": [
        "# display all the models results\n",
        "baselines_res.update({'catboost': metric_dict_cv})\n",
        "pd.DataFrame({model: metrics['mean'] for model, metrics in baselines_res.items()}).T.round(2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "cuda_env",
      "language": "python",
      "name": "cuda_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}